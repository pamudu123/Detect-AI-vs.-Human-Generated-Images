{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a75bd38",
   "metadata": {},
   "source": [
    "# Model Explainability (Grad-CAM)\n",
    "\n",
    "This notebook loads a pre-trained model and uses **Grad-CAM** (Gradient-weighted Class Activation Mapping) to visualize the regions of an image that influenced the model's prediction (AI-generated vs. Human).\n",
    "\n",
    "**Prerequisites:**\n",
    "- A trained model file (e.g., `best_model.pth`) must exist.\n",
    "- The `pytorch-grad-cam` library must be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d3524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Explainability libraries\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2af3359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "IMG_SIZE = 256\n",
    "\n",
    "MODEL_NAME = 'convnext_base.clip_laion2b_augreg_ft_in1k' \n",
    "# MODEL_NAME = 'vit_small_patch14_dinov2.lvd142m' # Example if you used this one\n",
    "\n",
    "MODEL_PATH = 'best_model.pth' \n",
    "\n",
    "DATA_DIR = \"/kaggle/input/ai-vs-human-generated-dataset/\" \n",
    "TEST_CSV_PATH = \"/kaggle/input/ai-vs-human-generated-dataset/test.csv\"\n",
    "\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd0a6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Transforms ---\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab981b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Model ---\n",
    "def load_trained_model(model_name, model_path, device):\n",
    "    print(f\"Creating model: {model_name}\")\n",
    "    model = timm.create_model(model_name, pretrained=False, num_classes=2)\n",
    "    \n",
    "    print(f\"Loading weights from {model_path}...\")\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    print(\"Weights loaded successfully.\")\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model = load_trained_model(MODEL_NAME, MODEL_PATH, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baaa5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Explainability Helpers ---\n",
    "def get_target_layer(model, model_name):\n",
    "    \"\"\"\n",
    "    Identifies the target layer for Grad-CAM based on model architecture.\n",
    "    \"\"\"\n",
    "    target_layer = None\n",
    "    \n",
    "    # ConvNeXt specific\n",
    "    if 'convnext' in model_name:\n",
    "        # usually the last block of the last stage\n",
    "        if hasattr(model, 'stages'):\n",
    "            target_layer = model.stages[-1].blocks[-1]\n",
    "            \n",
    "    # EfficientNet specific\n",
    "    elif 'efficientnet' in model_name:\n",
    "        if hasattr(model, 'conv_head'):\n",
    "            target_layer = model.conv_head\n",
    "            \n",
    "    # ResNet / General fallback\n",
    "    if target_layer is None:\n",
    "        # Try to find the last Conv2d layer\n",
    "        layers = [module for module in model.modules() if isinstance(module, nn.Conv2d)]\n",
    "        if layers:\n",
    "            target_layer = layers[-1]\n",
    "            \n",
    "    # If still None (e.g. ViT), GradCAM might need specific handling for Transformers (reshape_transform)\n",
    "    # For this snippet, we assume CNN-like or hybrid architectures supported by default\n",
    "    \n",
    "    print(f\"Target Layer for Grad-CAM: {target_layer}\")\n",
    "    return target_layer\n",
    "\n",
    "def run_grad_cam(model, img_tensor, target_layer):\n",
    "    \"\"\"\n",
    "    Generates Grad-CAM heatmap.\n",
    "    \"\"\"\n",
    "    # Initialize GradCAM\n",
    "    cam = GradCAM(model=model, target_layers=[target_layer])\n",
    "    \n",
    "    # Add batch dimension\n",
    "    input_tensor = img_tensor.unsqueeze(0).to(DEVICE)\n",
    "    \n",
    "    # We can target a specific class, or None for the highest predicted class\n",
    "    targets = None \n",
    "    \n",
    "    # Generate CAM\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "    \n",
    "    # Take the first image in the batch\n",
    "    grayscale_cam = grayscale_cam[0, :]\n",
    "    \n",
    "    return grayscale_cam\n",
    "\n",
    "def visualize_cam(img_tensor, heatmap, title=\"Grad-CAM\"):\n",
    "    \"\"\"\n",
    "    Plots the original image and the heatmap overlay.\n",
    "    \"\"\"\n",
    "    # Denormalize image for visualization\n",
    "    img_np = img_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img_np = std * img_np + mean\n",
    "    img_np = np.clip(img_np, 0, 1)\n",
    "    \n",
    "    # Create overlay\n",
    "    visualization = show_cam_on_image(img_np, heatmap, use_rgb=True)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img_np)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(visualization)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54c3c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run Inference & Explanation on a Sample ---\n",
    "\n",
    "df = pd.read_csv(TEST_CSV_PATH)\n",
    "sample_row = df.sample(1).iloc[0]\n",
    "# Adjust column name based on your CSV structure ('id' or 'file_name')\n",
    "fname = sample_row['id'] if 'id' in sample_row else sample_row['file_name']\n",
    "img_path = os.path.join(DATA_DIR, fname)\n",
    "\n",
    "# 2. Process and Explain\n",
    "if os.path.exists(img_path):\n",
    "    try:\n",
    "        # Load Image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        input_tensor = val_transform(image)\n",
    "        \n",
    "        # Get Prediction\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor.unsqueeze(0).to(DEVICE))\n",
    "            probs = torch.nn.functional.softmax(output, dim=1)\n",
    "            pred_idx = torch.argmax(probs).item()\n",
    "            conf = probs[0][pred_idx].item()\n",
    "            \n",
    "        label_map = {0: \"Real/Human\", 1: \"Fake/AI\"}\n",
    "        pred_label = label_map.get(pred_idx, str(pred_idx))\n",
    "        \n",
    "        print(f\"Prediction: {pred_label} (Confidence: {conf:.4f})\")\n",
    "        \n",
    "        # Run Grad-CAM\n",
    "        target_layer = get_target_layer(model, MODEL_NAME)\n",
    "        if target_layer:\n",
    "            heatmap = run_grad_cam(model, input_tensor, target_layer)\n",
    "            visualize_cam(input_tensor, heatmap, title=f\"Grad-CAM: {pred_label}\")\n",
    "        else:\n",
    "            print(\"Could not identify target layer for this model architecture.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during processing: {e}\")\n",
    "else:\n",
    "    print(\"Image file not found. Please check the path.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
